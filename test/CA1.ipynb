{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26815afb-0203-450c-9624-6cd8ba89c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXERCISE 1\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#get available data\n",
    "data=pd.read_csv(\"data.csv\")\n",
    "print(data.head()) \n",
    "\n",
    "url='data.csv'\n",
    "df=pd.read_csv(url)\n",
    "print(df.head())\n",
    "\n",
    "t={'I1':1,'I2':2}\n",
    "df=pd.DataFrame(t)\n",
    "\n",
    "#number of len,col,rows & count - shape(row[0] col[1])\n",
    "length=len(df)\n",
    "row=df.shape[0]\n",
    "col=df.shape[1]\n",
    "non_null_counts=df.count()\n",
    "\n",
    "#mean median mode std sum min max\n",
    "mean=df[attribute].mean()\n",
    "median=df[attribute].median()\n",
    "mode=df[attribute].mode() #printing print mean.values[0]\n",
    "std=df[attribute].std()\n",
    "statistics=df.describe() #all basic statistics\n",
    "sum=df['col'].sum()\n",
    "min=df['col'].min()\n",
    "max=df['col'].max()\n",
    "\n",
    "#excluding last col\n",
    "ex_last_col=df.iloc[:,:-1]\n",
    "#only last\n",
    "only_last=df.iloc[:,-1]\n",
    "\n",
    "#1st 5 and last 5\n",
    "first_5=df.head()\n",
    "last_5=df.tail()\n",
    "\n",
    "#number of times a particular category appears\n",
    "cat=df['category'].values_counts()\n",
    "\n",
    "#no missing value\n",
    "no_missing=df[df['col'].notna()]\n",
    "\n",
    "#remove col having missing values\n",
    "df_clean=df.dropna() #contain all the data removed missing value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6114c4-5919-4444-b52e-52dc8310316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXERCISE 2\n",
    "independent_var=df[['date','day']] #list of independent variabes \n",
    "dependent=df['name'] #can also be list\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "df['color_encoded']=encoder.fit_transform(df['color']) #print df - prints the encoded table with original attributes\n",
    "#one hot\n",
    "one_hot=pd.get_dummies(df)\n",
    "#train test\n",
    "x=df[['date','day']] #dep\n",
    "y=df['name'] #indep\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random=42)\n",
    "#min max normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "col_to_normalize='age'\n",
    "scaler=MinMaxScaler()\n",
    "df['Age_normalized']=scaler.fit_transfor(df[col_to_normalize]) #print df - age col is normalized\n",
    "#z-scale\n",
    "z_scale=df.copy()\n",
    "for column in z_scale.columns:\n",
    "    z_scale[column]=(z_scale[column]-z_scale[column].mean())/z_scale[column].std()\n",
    "print(z_scale)\n",
    "#replace none value with mean\n",
    "import numpy as np\n",
    "df.replace(0,np.nan,inplace=True)\n",
    "mean=df.mean()\n",
    "df.fillna(mean,inplave=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8bba2-c00a-451a-815a-8a6782a69204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXERCISE 3\n",
    "#VISUALIZATION\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis=np.array(data[\"col1\"])\n",
    "y_axis=np.array(data[\"col2\"])\n",
    "\n",
    "#Scatter plot\n",
    "plt.scatter(x_axis,y_axis,c=x_axis,s=20)\n",
    "plt.tilte(\"Scatter plot\")\n",
    "plt.xlabel(\"col1\")\n",
    "plt.ylabel(\"col2\")\n",
    "plt.show()\n",
    "\n",
    "#Line plot\n",
    "plt.plot(x_axis,color=\"Blues\") #or both axis\n",
    "plt.plot(y_axis,color=\"Pink\")\n",
    "plt.tilte(\"Line Plot\")\n",
    "plt.xlabel(\"col1\")\n",
    "plt.ylabel(\"col2\")\n",
    "plt.show()\n",
    "\n",
    "#bar \n",
    "plt.bar(x_axis,y_axis,color=\"Pink\")\n",
    "plt.tilte(\"Bar graph\")\n",
    "plt.xlabel(\"col1\")\n",
    "plt.ylabel(\"col2\")\n",
    "plt.show()\n",
    "\n",
    "#histogram\n",
    "plt.hist(x_axis,color=\"Pink\")\n",
    "plt.tilte(\"histogram\")\n",
    "plt.xlabel(\"col1\")\n",
    "plt.ylabel(\"col2\")\n",
    "plt.show()\n",
    "\n",
    "#boxplot\n",
    "plt.box(x_axis,color=\"Pink\")\n",
    "plt.tilte(\"boxplot\")\n",
    "plt.xlabel(\"col1\")\n",
    "plt.ylabel(\"col2\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "####Pearsonâ€™s Correlation Coefficient function\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "data[\"Target\"]=encoder.fit_transform(data[\"Target\"])\n",
    "plt.figure(figsize=(36,36))\n",
    "cor_matrix1=data.corr(numeric_only=True)\n",
    "sns.heatmap(cor_matrix1,annot=True,cmap=plt.cm.Reds)\n",
    "plt.show()\n",
    "\n",
    "cor_target=abs(cor_matrix1[\"Target\"])\n",
    "cor_target\n",
    "\n",
    "relevant_features=cor_target[cor_target>0.38]\n",
    "relevant_features\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "x=data.iloc[:,:-1]\n",
    "y=data.iloc[:,-1]\n",
    "model=DecisionTreeClassifier()\n",
    "rfe=RFE(model,n_features_to_select=10)\n",
    "fit=rfe.fit(x,y)\n",
    "print(\"Num Features:\",fit.n_features_)\n",
    "print(\"Selected Features:\",fit.support_)\n",
    "print(\"Feature Ranking:\",fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8a514-6380-48be-9419-404e465a56da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXERCISE 4\n",
    "!pip install mlxtend\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "#without one-hot encoding\n",
    "transactions = {\n",
    "    'I1': [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
    "    'I2': [1, 1, 1, 1, 0, 1, 0, 1, 1],\n",
    "    'I3': [0, 0, 1, 0, 1, 1, 1, 1, 1],\n",
    "    'I4': [0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
    "    'I5': [1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(transactions)\n",
    "print(df)\n",
    "\n",
    "frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)\n",
    "\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.2)\n",
    "\n",
    "\n",
    "# Using TransactionEncoder to one-hot encode the data\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data).transform(data)\n",
    "transactions = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "print(transactions)\n",
    "\n",
    "# Apply apriori algorithm\n",
    "frequent_itemsets = apriori(transactions, min_support=0.1, use_colnames=True)\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Extract association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.2)\n",
    "print(rules)\n",
    "\n",
    "# Filter rules where the consequent is a disease\n",
    "disease_rules = rules[rules['consequents'].apply(lambda x: any(item in x for item in ['flu', 'cold', 'migraine']))]\n",
    "\n",
    "# Filter rules where the consequent is exactly one of the diseases\n",
    "disease_rules_only = rules[\n",
    "    rules['consequents'].apply(lambda x: len(x) == 1 and any(item in x for item in ['flu', 'cold', 'migraine']))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29107dc7-41de-4964-a636-a47788034353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXERCISE 5\n",
    "#FP GROWTH\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "transactions = [\n",
    "    ['Bread', 'Milk', 'Beer'],\n",
    "    ['Bread', 'Diapers', 'Milk'],\n",
    "    ['Milk', 'Diapers', 'Bread'],\n",
    "    ['Bread', 'Milk', 'Diapers', 'Beer'],\n",
    "    ['Diapers', 'Beer']\n",
    "]\n",
    "\n",
    "transaction_df = pd.DataFrame(transactions)\n",
    "one_hot = transaction_df.stack().groupby(level=0).value_counts().unstack().fillna(0).astype(int)\n",
    "min_support = 0.4 \n",
    "frequent_itemsets = fpgrowth(one_hot, min_support=min_support, use_colnames=True)\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "min_confidence = 0.7  \n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
